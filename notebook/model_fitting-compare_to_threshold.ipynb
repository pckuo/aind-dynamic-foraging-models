{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import glob\n",
    "import pickle\n",
    "\n",
    "import numpy as np\n",
    "from aind_behavior_gym.dynamic_foraging.task import CoupledBlockTask, UncoupledBlockTask\n",
    "from aind_dynamic_foraging_models.generative_model import ForagerCollection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pynwb import NWBHDF5IO\n",
    "\n",
    "LOCAL_NWB_TMP = \"/data/foraging_nwb_bonsai\"\n",
    "\n",
    "def get_nwb_from_local_tmp(session_id):\n",
    "    \"\"\"Get NWB file from session_id.\n",
    "\n",
    "    Overwrite this function to get NWB file from other places.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    session_id : _type_\n",
    "        _description_\n",
    "    \"\"\"\n",
    "    io = NWBHDF5IO(f\"{LOCAL_NWB_TMP}/{session_id}.nwb\", mode=\"r\")\n",
    "    nwb = io.read()\n",
    "    return nwb\n",
    "\n",
    "\n",
    "def get_history_from_nwb(nwb):\n",
    "    \"\"\"Get choice and reward history from nwb file\n",
    "    \n",
    "    #TODO move this to aind-behavior-nwb-util\n",
    "    \"\"\"\n",
    "\n",
    "    df_trial = nwb.trials.to_dataframe()\n",
    "\n",
    "    autowater_offered = (df_trial.auto_waterL == 1) | (df_trial.auto_waterR == 1)\n",
    "    choice_history = df_trial.animal_response.map({0: 0, 1: 1, 2: np.nan}).values\n",
    "    reward_history = df_trial.rewarded_historyL | df_trial.rewarded_historyR\n",
    "    p_reward = [\n",
    "        df_trial.reward_probabilityL.values,\n",
    "        df_trial.reward_probabilityR.values,\n",
    "    ]\n",
    "    random_number = [\n",
    "        df_trial.reward_random_number_left.values,\n",
    "        df_trial.reward_random_number_right.values,\n",
    "    ]\n",
    "\n",
    "    baiting = False if \"without baiting\" in nwb.protocol.lower() else True\n",
    "\n",
    "    return (\n",
    "        baiting,\n",
    "        choice_history,\n",
    "        reward_history,\n",
    "        p_reward,\n",
    "        autowater_offered,\n",
    "        random_number,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from logging import BASIC_FORMAT\n",
    "from socket import AI_CANONNAME\n",
    "\n",
    "\n",
    "# subject_id = '781370'  # uncoupled, no baiting\n",
    "# subject_id = '764769'  # uncoupled, baiting\n",
    "# subject_id = '776293'  # uncoupled, baiting\n",
    "subject_id = '769884'  # uncoupled, baiting\n",
    "\n",
    "\n",
    "nll_ctt = []\n",
    "nll_hattori = []\n",
    "aic_ctt = []\n",
    "aic_hattori = []\n",
    "bic_ctt = []\n",
    "bic_hattori = []\n",
    "\n",
    "for session_name in sorted(glob.glob(f'{LOCAL_NWB_TMP}/{subject_id}_*'), reverse=True):\n",
    "    print('############################################')\n",
    "    session_id = session_name.split('/')[-1].split('.')[0]\n",
    "    print(session_id)\n",
    "\n",
    "    nwb = get_nwb_from_local_tmp(session_id=session_id)\n",
    "    (\n",
    "        baiting,\n",
    "        choice_history,\n",
    "        reward_history,\n",
    "        _,\n",
    "        autowater_offered,\n",
    "        random_number,\n",
    "    ) = get_history_from_nwb(nwb)\n",
    "\n",
    "\n",
    "    # Remove NaNs\n",
    "    ignored = np.isnan(choice_history)\n",
    "    choice_history = choice_history[~ignored]\n",
    "    reward_history = reward_history[~ignored].to_numpy()\n",
    "    \n",
    "    # handle invalid sessions if there are too few trials\n",
    "    # -- Skip if len(valid trials) < 50 --\n",
    "    if len(choice_history) < 50:\n",
    "        fit_result = {\n",
    "            \"status\": \"skipped. valid trials < 50\",\n",
    "            \"upload_figs_s3\": {},\n",
    "            \"upload_pkls_s3\": {},\n",
    "            \"upload_record_docDB\": {},\n",
    "        }\n",
    "        print(f\"Skipping session {session_id} due to too few trials n={len(choice_history)}.\")\n",
    "    \n",
    "    else:\n",
    "        # -- Initialize model --\n",
    "        # forager = ForagerCollection().get_forager(\n",
    "        #     agent_class_name=\"ForagerCompareThreshold\",\n",
    "        #     agent_kwargs={\n",
    "        #         'choice_kernel': \"none\",\n",
    "        #     },\n",
    "        # )\n",
    "        forager_ctt = ForagerCollection().get_preset_forager(\"CompareToThreshold\")\n",
    "        fitting_result_ctt, _ = forager_ctt.fit(\n",
    "            choice_history,\n",
    "            reward_history,\n",
    "            clamp_params={\n",
    "                # \"biasL\": 0, \n",
    "                # \"softmax_inverse_temperature\": 5.0\n",
    "            },\n",
    "            DE_kwargs=dict(\n",
    "                workers=4, \n",
    "                disp=True, \n",
    "                seed=np.random.default_rng(42)\n",
    "            ),\n",
    "            # k_fold_cross_validation=None\n",
    "        )\n",
    "\n",
    "        forager_hattori = ForagerCollection().get_preset_forager(\"Hattori2019\")\n",
    "        fitting_result_hattori, _ = forager_hattori.fit(\n",
    "            choice_history,\n",
    "            reward_history,\n",
    "            DE_kwargs=dict(\n",
    "                workers=4, \n",
    "                disp=True, \n",
    "                seed=np.random.default_rng(42)\n",
    "            ),\n",
    "            # k_fold_cross_validation=None\n",
    "        )\n",
    "\n",
    "\n",
    "        # Check fitted parameters\n",
    "        for model_ind, fitting_result in enumerate([fitting_result_ctt, fitting_result_hattori]):\n",
    "            fit_names = fitting_result.fit_settings[\"fit_names\"]\n",
    "            print(f'Model: {['CompareToThreshold', 'Hattori'][model_ind]}')\n",
    "            print(f'fitting results keys: {fitting_result_ctt.keys()}')\n",
    "            print(f\"Num of trials: {len(choice_history)}\")\n",
    "            print(f\"Likelihood-Per-Trial: {fitting_result.LPT}\")\n",
    "            print(f\"Negative Log-Likelihood: {-1*fitting_result.log_likelihood}\")\n",
    "            print(f\"AIC: {fitting_result.AIC}\")\n",
    "            print(f\"BIC: {fitting_result.BIC}\")\n",
    "            print(f\"Prediction accuracy full dataset: {fitting_result.prediction_accuracy}\")\n",
    "            print(f\"Fitted parameters: {fit_names}\")\n",
    "            print(f'Fitted:       {[f\"{num:.4f}\" for num in fitting_result.x]}\\n')\n",
    "\n",
    "        # append results\n",
    "        nll_ctt.append(-1 * fitting_result_ctt.log_likelihood)\n",
    "        nll_hattori.append(-1 * fitting_result_hattori.log_likelihood)\n",
    "        aic_ctt.append(fitting_result_ctt.AIC)\n",
    "        aic_hattori.append(fitting_result_hattori.AIC)\n",
    "        bic_ctt.append(fitting_result_ctt.BIC)\n",
    "        bic_hattori.append(fitting_result_hattori.BIC)\n",
    "\n",
    "        # # plot fitted session\n",
    "        # fig_fitting_ctt, axes_ctt = forager_ctt.plot_fitted_session(if_plot_latent=True)\n",
    "        # fig_fitting_hattori, axes_hattori = forager_hattori.plot_fitted_session(if_plot_latent=True)\n",
    "\n",
    "        # fig_fitting_ctt.savefig(f'/results/{session_id}-ctt.png', dpi=150)\n",
    "        # fig_fitting_hattori.savefig(f'/results/{session_id}-hattori.png', dpi=150)\n",
    "\n",
    "# convert to numpy arrays\n",
    "nll_ctt = np.array(nll_ctt)\n",
    "nll_hattori = np.array(nll_hattori)\n",
    "aic_ctt = np.array(aic_ctt)\n",
    "aic_hattori = np.array(aic_hattori)\n",
    "bic_ctt = np.array(bic_ctt)\n",
    "bic_hattori = np.array(bic_hattori)\n",
    "\n",
    "# save data\n",
    "with open(f'/results/{subject_id}_model_fits.pkl', 'wb') as f:\n",
    "    pickle.dump({\n",
    "        'nll_ctt': nll_ctt,\n",
    "        'nll_hattori': nll_hattori,\n",
    "        'aic_ctt': aic_ctt,\n",
    "        'aic_hattori': aic_hattori,\n",
    "        'bic_ctt': bic_ctt,\n",
    "        'bic_hattori': bic_hattori,\n",
    "    }, f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "def plot_model_comparison(\n",
    "    hattori_nll, ctt_nll, \n",
    "    hattori_aic, ctt_aic, \n",
    "    hattori_bic, ctt_bic, \n",
    "    subject_id,\n",
    "    figsize=(20, 6)\n",
    "):\n",
    "    \"\"\"\n",
    "    Create violin plots comparing model fit metrics between Hattori and CTT models.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    hattori_nll, ctt_nll : array-like, shape (n_sessions, 1)\n",
    "        Negative log-likelihood values for each model\n",
    "    hattori_aic, ctt_aic : array-like, shape (n_sessions, 1)\n",
    "        AIC values for each model\n",
    "    hattori_bic, ctt_bic : array-like, shape (n_sessions, 1)\n",
    "        BIC values for each model\n",
    "    figsize : tuple\n",
    "        Figure size (width, height)\n",
    "    \"\"\"\n",
    "    \n",
    "    # Ensure arrays are 1D\n",
    "    hattori_nll = np.array(hattori_nll).flatten()\n",
    "    ctt_nll = np.array(ctt_nll).flatten()\n",
    "    hattori_aic = np.array(hattori_aic).flatten()\n",
    "    ctt_aic = np.array(ctt_aic).flatten()\n",
    "    hattori_bic = np.array(hattori_bic).flatten()\n",
    "    ctt_bic = np.array(ctt_bic).flatten()\n",
    "    \n",
    "    n_sessions = len(hattori_nll)\n",
    "    \n",
    "    # Create figure with subplots\n",
    "    fig, axes = plt.subplots(1, 3, figsize=figsize)\n",
    "    fig.suptitle(\n",
    "        f'Model Comparison for {subject_id}: Q-learning (Hattori) vs Foraging (compare-to-threshold)', \n",
    "        fontsize=14)\n",
    "    \n",
    "    # Define metrics and their data\n",
    "    metrics = ['NLL', 'AIC', 'BIC']\n",
    "    hattori_data = [hattori_nll, hattori_aic, hattori_bic]\n",
    "    ctt_data = [ctt_nll, ctt_aic, ctt_bic]\n",
    "    \n",
    "    # Colors for models\n",
    "    colors = {'Hattori': '#3498db', 'CTT': '#e74c3c'}\n",
    "    \n",
    "    # Plot each metric\n",
    "    for idx, (ax, metric, h_data, c_data) in enumerate(zip(axes, metrics, hattori_data, ctt_data)):\n",
    "        # Prepare data for violin plot\n",
    "        data_dict = {\n",
    "            'Model': ['Hattori'] * n_sessions + ['CTT'] * n_sessions,\n",
    "            'Value': np.concatenate([h_data, c_data]),\n",
    "            'Session': list(range(n_sessions)) * 2\n",
    "        }\n",
    "        df = pd.DataFrame(data_dict)\n",
    "        \n",
    "        # Create violin plot\n",
    "        parts = ax.violinplot([h_data, c_data], positions=[0, 1], \n",
    "                             showmeans=True, showmedians=True, showextrema=True)\n",
    "        \n",
    "        # Customize violin colors\n",
    "        for pc, color in zip(parts['bodies'], [colors['Hattori'], colors['CTT']]):\n",
    "            pc.set_facecolor(color)\n",
    "            pc.set_alpha(0.6)\n",
    "            pc.set_edgecolor('black')\n",
    "            pc.set_linewidth(1)\n",
    "        \n",
    "        # Customize other elements\n",
    "        for partname in ('cbars', 'cmins', 'cmaxes', 'cmedians', 'cmeans'):\n",
    "            if partname in parts:\n",
    "                parts[partname].set_edgecolor('black')\n",
    "                parts[partname].set_linewidth(1.5)\n",
    "        \n",
    "        # Add individual points\n",
    "        x_hattori = np.random.normal(0, 0.04, n_sessions)\n",
    "        x_ctt = np.random.normal(1, 0.04, n_sessions)\n",
    "        \n",
    "        ax.scatter(x_hattori, h_data, color=colors['Hattori'], \n",
    "                  alpha=0.8, s=30, edgecolor='black', linewidth=0.5, zorder=5)\n",
    "        ax.scatter(x_ctt, c_data, color=colors['CTT'], \n",
    "                  alpha=0.8, s=30, edgecolor='black', linewidth=0.5, zorder=5)\n",
    "        \n",
    "        # Add connecting lines between corresponding sessions\n",
    "        for i in range(n_sessions):\n",
    "            ax.plot([x_hattori[i], x_ctt[i]], [h_data[i], c_data[i]], \n",
    "                   color='gray', alpha=0.3, linewidth=1, zorder=1)\n",
    "        \n",
    "        # Customize axes\n",
    "        ax.set_ylabel(f'{metric}', fontsize=12, fontweight='bold')\n",
    "        ax.set_xticks([0, 1])\n",
    "        ax.set_xticklabels(['Hattori', 'CTT'], fontsize=11)\n",
    "        ax.grid(True, alpha=0.3, axis='y')\n",
    "        \n",
    "        # Add metric statistics\n",
    "        h_mean, h_std = np.mean(h_data), np.std(h_data)\n",
    "        c_mean, c_std = np.mean(c_data), np.std(c_data)\n",
    "        \n",
    "        stats_text = f'Hattori: {h_mean:.2f} ± {h_std:.2f}\\n'\n",
    "        stats_text += f'CTT: {c_mean:.2f} ± {c_std:.2f}'\n",
    "        ax.text(0.02, 0.98, stats_text, transform=ax.transAxes, \n",
    "               verticalalignment='top', fontsize=14,\n",
    "               bbox=dict(boxstyle='round', facecolor='white', alpha=0.8))\n",
    "        \n",
    "        # Add x-label\n",
    "        ax.set_xlabel('Model', fontsize=12, fontweight='bold')\n",
    "    \n",
    "    # Adjust layout\n",
    "    plt.tight_layout()\n",
    "    \n",
    "    return fig, axes\n",
    "\n",
    "\n",
    "def plot_model_comparison_difference(\n",
    "    hattori_nll, ctt_nll, \n",
    "    hattori_aic, ctt_aic, \n",
    "    hattori_bic, ctt_bic, \n",
    "    subject_id,\n",
    "    figsize=(20, 6)\n",
    "):\n",
    "    \"\"\"\n",
    "    Create violin plots showing the distribution of differences between Hattori and CTT models.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    hattori_nll, ctt_nll : array-like, shape (n_sessions, 1)\n",
    "        Negative log-likelihood values for each model\n",
    "    hattori_aic, ctt_aic : array-like, shape (n_sessions, 1)\n",
    "        AIC values for each model\n",
    "    hattori_bic, ctt_bic : array-like, shape (n_sessions, 1)\n",
    "        BIC values for each model\n",
    "    subject_id : str\n",
    "        Subject identifier for the title\n",
    "    figsize : tuple\n",
    "        Figure size (width, height)\n",
    "    \"\"\"\n",
    "    \n",
    "    # Ensure arrays are 1D\n",
    "    hattori_nll = np.array(hattori_nll).flatten()\n",
    "    ctt_nll = np.array(ctt_nll).flatten()\n",
    "    hattori_aic = np.array(hattori_aic).flatten()\n",
    "    ctt_aic = np.array(ctt_aic).flatten()\n",
    "    hattori_bic = np.array(hattori_bic).flatten()\n",
    "    ctt_bic = np.array(ctt_bic).flatten()\n",
    "    \n",
    "    n_sessions = len(hattori_nll)\n",
    "    \n",
    "    # Calculate differences (CTT - Hattori)\n",
    "    # Negative values mean Hattori is better (lower is better for these metrics)\n",
    "    diff_nll = ctt_nll - hattori_nll\n",
    "    diff_aic = ctt_aic - hattori_aic\n",
    "    diff_bic = ctt_bic - hattori_bic\n",
    "\n",
    "    # Create figure with subplots\n",
    "    fig, axes = plt.subplots(1, 3, figsize=figsize, dpi=150)\n",
    "    fig.suptitle(\n",
    "        f'Model Comparison for {subject_id}' +\n",
    "        ', difference = CTT - Hattori (negative values favor CTT)', \n",
    "        fontsize=16)\n",
    "    \n",
    "    # Define metrics and their data\n",
    "    metrics = ['NLL', 'AIC', 'BIC']\n",
    "    diff_data = [diff_nll, diff_aic, diff_bic]\n",
    "    \n",
    "    # Color for difference plot\n",
    "    diff_color = '#9b59b6'\n",
    "    \n",
    "    # Plot each metric\n",
    "    for idx, (ax, metric, diff) in enumerate(zip(axes, metrics, diff_data)):\n",
    "        # Create violin plot for difference\n",
    "        parts = ax.violinplot([diff], positions=[0], \n",
    "                             showmeans=True, showmedians=True, showextrema=True)\n",
    "        \n",
    "        # Customize violin colors\n",
    "        for pc in parts['bodies']:\n",
    "            pc.set_facecolor(diff_color)\n",
    "            pc.set_alpha(0.6)\n",
    "            pc.set_edgecolor('black')\n",
    "            pc.set_linewidth(1)\n",
    "        \n",
    "        # Customize other elements\n",
    "        for partname in ('cbars', 'cmins', 'cmaxes', 'cmedians', 'cmeans'):\n",
    "            if partname in parts:\n",
    "                parts[partname].set_edgecolor('black')\n",
    "                parts[partname].set_linewidth(1.5)\n",
    "        \n",
    "        # Add horizontal line at y=0 (no difference)\n",
    "        ax.axhline(y=0, color='black', linestyle='--', alpha=0.5, linewidth=2)\n",
    "        \n",
    "        # Add individual points\n",
    "        x_positions = np.random.normal(0, 0.04, n_sessions)\n",
    "        \n",
    "        # Color points based on which model is better\n",
    "        point_colors = ['#3498db' if d < 0 else '#e74c3c' for d in diff]\n",
    "        \n",
    "        ax.scatter(x_positions, diff, color=point_colors, \n",
    "                  alpha=0.8, s=40, edgecolor='black', linewidth=0.5, zorder=5)\n",
    "        \n",
    "        # # Add vertical lines from 0 to each point\n",
    "        # for i in range(n_sessions):\n",
    "        #     ax.plot([x_positions[i], x_positions[i]], [0, diff[i]], \n",
    "        #            color='gray', alpha=0.3, linewidth=0.8, zorder=1)\n",
    "        \n",
    "        # Customize axes\n",
    "        ax.set_ylabel(f'Δ{metric} (CTT - Hattori)', fontsize=14, fontweight='bold')\n",
    "        ax.set_xticks([])\n",
    "        # ax.set_xticklabels(['Difference'], fontsize=11)\n",
    "        ax.grid(True, alpha=0.3, axis='y')\n",
    "        \n",
    "        # Add metric statistics\n",
    "        mean_diff = np.mean(diff)\n",
    "        std_diff = np.std(diff)\n",
    "        n_hattori_better = np.sum(diff > 0)\n",
    "        n_ctt_better = np.sum(diff < 0)\n",
    "        n_equal = np.sum(diff == 0)\n",
    "        \n",
    "        stats_text = f'Mean difference: {mean_diff:.2f} ± {std_diff:.2f}\\n'\n",
    "        stats_text += f'Hattori better: {n_hattori_better}/{n_sessions} sessions\\n'\n",
    "        stats_text += f'CTT better: {n_ctt_better}/{n_sessions} sessions'\n",
    "        if n_equal > 0:\n",
    "            stats_text += f'\\nEqual: {n_equal}/{n_sessions} sessions'\n",
    "        \n",
    "        ax.text(0.02, 0.98, stats_text, transform=ax.transAxes, \n",
    "               verticalalignment='top', fontsize=14,\n",
    "               bbox=dict(boxstyle='round', facecolor='white', alpha=0.8))\n",
    "        \n",
    "        # Add x-label\n",
    "        # ax.set_xlabel('Model Difference', fontsize=12, fontweight='bold')\n",
    "    \n",
    "    # Adjust layout\n",
    "    fig.tight_layout()\n",
    "    \n",
    "    return fig, axes\n",
    "\n",
    "\n",
    "# Create the plot\n",
    "fig, axes = plot_model_comparison(\n",
    "    nll_hattori, nll_ctt, \n",
    "    aic_hattori, aic_ctt, \n",
    "    bic_hattori, bic_ctt,\n",
    "    subject_id=subject_id,\n",
    ")\n",
    "fig, axes = plot_model_comparison_difference(\n",
    "    nll_hattori, nll_ctt, \n",
    "    aic_hattori, aic_ctt, \n",
    "    bic_hattori, bic_ctt,\n",
    "    subject_id=subject_id,\n",
    ")\n",
    "\n",
    "\n",
    "# Print summary statistics\n",
    "print(\"Model Comparison Summary (Difference = CTT - Hattori, negative favors CTT):\")\n",
    "n_sessions = len(nll_hattori)\n",
    "print(f\"Number of sessions: {n_sessions}\")\n",
    "\n",
    "print(\"-\" * 50)\n",
    "print(f\"NLL - Hattori: {np.mean(nll_hattori):.2f} ± {np.std(nll_hattori):.2f}\")\n",
    "print(f\"NLL - CTT: {np.mean(nll_ctt):.2f} ± {np.std(nll_ctt):.2f}\")\n",
    "print(f\"AIC - Hattori: {np.mean(aic_hattori):.2f} ± {np.std(aic_hattori):.2f}\")\n",
    "print(f\"AIC - CTT: {np.mean(aic_ctt):.2f} ± {np.std(aic_ctt):.2f}\")\n",
    "print(f\"BIC - Hattori: {np.mean(bic_hattori):.2f} ± {np.std(bic_hattori):.2f}\")\n",
    "print(f\"BIC - CTT: {np.mean(bic_ctt):.2f} ± {np.std(bic_ctt):.2f}\")\n",
    "\n",
    "print(f\"\\nΔNLL: {np.mean(nll_ctt - nll_hattori):.2f} ± {np.std(nll_ctt - nll_hattori):.2f}\")\n",
    "print(f\"ΔAIC: {np.mean(aic_ctt - aic_hattori):.2f} ± {np.std(aic_ctt - aic_hattori):.2f}\")\n",
    "print(f\"ΔBIC: {np.mean(bic_ctt - bic_hattori):.2f} ± {np.std(bic_ctt - bic_hattori):.2f}\")\n",
    "\n",
    "print(\"\\nSessions where CTT performs better:\")\n",
    "print(f\"NLL: {np.sum((nll_ctt - nll_hattori) < 0)}/{n_sessions}\")\n",
    "print(f\"AIC: {np.sum((aic_ctt - aic_hattori) < 0)}/{n_sessions}\")\n",
    "print(f\"BIC: {np.sum((bic_ctt - bic_hattori) < 0)}/{n_sessions}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -- Load data --\n",
    "# session_id = '781896_2025-04-10_14-11-57'\n",
    "\n",
    "# session_id = '781370_2025-02-03_11-09-28'\n",
    "# session_id = '781370_2025-02-05_11-25-51'\n",
    "session_id = '781370_2025-03-20_11-12-56'\n",
    "# session_id = '781370_2025-02-14_11-26-21'\n",
    "# session_id = '781370_2025-02-17_11-11-23'\n",
    "\n",
    "# session_id = '784806_2025-04-21_13-13-39'\n",
    "\n",
    "# session_id = '770527_2025-01-15_11-01-55'\n",
    "\n",
    "# session_id = '739977_2024-10-03_09-04-34'\n",
    "\n",
    "# session_id = '786866_2025-04-10_11-24-47'\n",
    "\n",
    "\n",
    "nwb = get_nwb_from_local_tmp(session_id=session_id)\n",
    "(\n",
    "    baiting,\n",
    "    choice_history,\n",
    "    reward_history,\n",
    "    _,\n",
    "    autowater_offered,\n",
    "    random_number,\n",
    ") = get_history_from_nwb(nwb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove NaNs\n",
    "ignored = np.isnan(choice_history)\n",
    "choice_history = choice_history[~ignored]\n",
    "reward_history = reward_history[~ignored].to_numpy()\n",
    "\n",
    "# -- Skip if len(valid trials) < 50 --\n",
    "if len(choice_history) < 50:\n",
    "    fit_result = {\n",
    "        \"status\": \"skipped. valid trials < 50\",\n",
    "        \"upload_figs_s3\": {},\n",
    "        \"upload_pkls_s3\": {},\n",
    "        \"upload_record_docDB\": {},\n",
    "    }\n",
    "\n",
    "# -- Initialize model --\n",
    "# forager = ForagerCollection().get_forager(\n",
    "#     agent_class_name=\"ForagerCompareThreshold\",\n",
    "#     agent_kwargs={\n",
    "#         'choice_kernel': \"none\",\n",
    "#     },\n",
    "# )\n",
    "\n",
    "forager_ctt = ForagerCollection().get_preset_forager(\"CompareToThreshold\")\n",
    "fitting_result_ctt, _ = forager_ctt.fit(\n",
    "    choice_history,\n",
    "    reward_history,\n",
    "    clamp_params={\n",
    "        # \"biasL\": 0, \n",
    "        # \"softmax_inverse_temperature\": 5.0\n",
    "    },\n",
    "    DE_kwargs=dict(\n",
    "        workers=4, \n",
    "        disp=True, \n",
    "        seed=np.random.default_rng(42)\n",
    "    ),\n",
    "    # k_fold_cross_validation=None\n",
    ")\n",
    "\n",
    "\n",
    "forager_hattori = ForagerCollection().get_preset_forager(\"Hattori2019\")\n",
    "fitting_result_hattori, _ = forager_hattori.fit(\n",
    "    choice_history,\n",
    "    reward_history,\n",
    "    DE_kwargs=dict(\n",
    "        workers=4, \n",
    "        disp=True, \n",
    "        seed=np.random.default_rng(42)\n",
    "    ),\n",
    "    # k_fold_cross_validation=None\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check fitted parameters\n",
    "for model_ind, fitting_result in enumerate([fitting_result_ctt, fitting_result_hattori]):\n",
    "    fit_names = fitting_result.fit_settings[\"fit_names\"]\n",
    "    print(f'Model: {['CompareToThreshold', 'Hattori'][model_ind]}')\n",
    "    print(f\"Num of trials: {len(choice_history)}\")\n",
    "    print(f\"Likelihood-Per-Trial: {fitting_result.LPT}\")\n",
    "    print(f\"AIC: {fitting_result.AIC}\")\n",
    "    print(f\"BIC: {fitting_result.BIC}\")\n",
    "    print(f\"Prediction accuracy full dataset: {fitting_result.prediction_accuracy}\")\n",
    "    print(f\"Fitted parameters: {fit_names}\")\n",
    "    print(f'Fitted:       {[f\"{num:.4f}\" for num in fitting_result.x]}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig_fitting, axes = forager_ctt.plot_fitted_session(if_plot_latent=True)\n",
    "fig_fitting, axes = forager_hattori.plot_fitted_session(if_plot_latent=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
